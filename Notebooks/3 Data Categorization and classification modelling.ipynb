{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predection of Depression by different gait and Balance parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/naveengv7/Depression_Gait_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "# Path of Raw Data on the computer\n",
    "DATA_PATH = r'/content/Depression_Gait_balance/Data/Data_after_imputation_winsoring/All_Data_After_Imputation_Winsoring_Classification.xlsx'\n",
    "# import DATA after having the LABLE (Frist Columen is Y) columnes 2 and 3 are the neuomerical data of predectors form thim Y calculated)\n",
    "df = pd.read_excel(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y Variables\n",
    "Y_Var = ['CurrentPOMSdepressionClasses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic_variables\n",
    "Demographic_var = ['Sex', 'Age', 'Heightcm', 'WeightinKG', 'CalculatedBMI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gait_Variables\n",
    "ANTICEPATORY_POSTURE = ['AnticipatoryPosturalAdjustmentAPADurations','AnticipatoryPosturalAdjustmentFirstStepDurations','AnticipatoryPosturalAdjustmentFirstStepRangeofMotiondegrees','AnticipatoryPosturalAdjustmentForwardAPAPeakms2','AnticipatoryPosturalAdjustmentLateralAPAPeakms2']\n",
    "BACK_ROM = ['GaitJointBackRightLat.BendMax.degreesmean','GaitJointBackRightLat.BendMax.degreesstd','GaitJointBackLeftLat.BendMax.degreesmean','GaitJointBackLeftLat.BendMax.degreesstd','GaitJointBackRLLatBendRangedegreesmean','GaitJointBackRLLatBendRangedegreesstd','GaitJointBackFlexExtMax.degreesmean','GaitJointBackFlexExtMax.degreesstd','GaitJointBackFlexExtMin.degreesmean','GaitJointBackFlexExtMin.degreesstd','GaitJointBackFlexExtRangedegreesmean','GaitJointBackFlexExtRangedegreesstd','GaitJointBackRightRotMax.degreesmean','GaitJointBackRightRotMax.degreesstd','GaitJointBackLeftRotMax.degreesmean','GaitJointBackLeftRotMax.degreesstd','GaitJointBackRLRotRangedegreesmean','GaitJointBackRLRotRangedegreesstd']\n",
    "NECK_ROM = ['GaitJointNeckRightLat.BendMax.degreesmean','GaitJointNeckRightLat.BendMax.degreesstd','GaitJointNeckLeftLat.BendMax.degreesmean','GaitJointNeckLeftLat.BendMax.degreesstd','GaitJointNeckRLLat.BendRangedegreesmean','GaitJointNeckRLLat.BendRangedegreesstd','GaitJointNeckFlexExtMax.degreesmean','GaitJointNeckFlexExtMax.degreesstd','GaitJointNeckFlexExtMin.degreesmean','GaitJointNeckFlexExtMin.degreesstd','GaitJointNeckFlexExtRangedegreesmean','GaitJointNeckFlexExtRangedegreesstd','GaitJointNeckRightRotMax.degreesmean','GaitJointNeckRightRotMax.degreesstd','GaitJointNeckLeftRotMax.degreesmean','GaitJointNeckLeftRotMax.degreesstd','GaitJointNeckRLRotRangedegreesmean','GaitJointNeckRLRotRangedegreesstd']\n",
    "CADENCE = ['GaitLowerLimbCadenceLstepsminmean','GaitLowerLimbCadenceLstepsminstd','GaitLowerLimbCadenceRstepsminmean','GaitLowerLimbCadenceRstepsminstd','Avgcadence','Cadenceasymmetry']\n",
    "DOUBLE_LIMB_SUPPORT_GCT = ['GaitLowerLimbDoubleSupportLGCTmean','GaitLowerLimbDoubleSupportLGCTstd','GaitLowerLimbDoubleSupportRGCTmean','GaitLowerLimbDoubleSupportRGCTstd','AvgdoublelegsupportofGCT','AsymetriesdoublelegsupportGCT']\n",
    "MIDSWING = ['GaitLowerLimbElevationatMidswingLcmmean','GaitLowerLimbElevationatMidswingLcmstd','GaitLowerLimbElevationatMidswingRcmmean','GaitLowerLimbElevationatMidswingRcmstd','Avgmidswingelevation','Asymetrymidswingelevation']\n",
    "GAIT_CYCLE_DURATION = ['GaitLowerLimbGaitCycleDurationLsmean','GaitLowerLimbGaitCycleDurationLsstd','GaitLowerLimbGaitCycleDurationRsmean','GaitLowerLimbGaitCycleDurationRsstd','Avggaitcycleduration','Asymmetrygaitcycleduration']\n",
    "GAIT_SPEED = ['GaitLowerLimbGaitSpeedLmsmean','GaitLowerLimbGaitSpeedLmsstd','GaitLowerLimbGaitSpeedRmsmean','GaitLowerLimbGaitSpeedRmsstd','Avggaitspeed','Asymmetrygaitspeed']\n",
    "GAIT_LATERAL_VARIATION = ['GaitLowerLimbLateralStepVariabilityLcm','GaitLowerLimbLateralStepVariabilityRcm','Avgstepvariability','Asymmetrystepvariability']\n",
    "CIRCUMDUCTION_GAIT = ['GaitLowerLimbCircumductionLcmmean','GaitLowerLimbCircumductionLcmstd','GaitLowerLimbCircumductionRcmmean','GaitLowerLimbCircumductionRcmstd','Avgcircumduction','Asymmetrycircumdunction']\n",
    "FOOT_STRIKE = ['GaitLowerLimbFootStrikeAngleLdegreesmean','GaitLowerLimbFootStrikeAngleLdegreesstd','GaitLowerLimbFootStrikeAngleRdegreesmean','GaitLowerLimbFootStrikeAngleRdegreesstd','Avgfootstrikeangle','Asymmetryfootstrikeangle']\n",
    "TOE_OFF = ['GaitLowerLimbToeOffAngleLdegreesmean','GaitLowerLimbToeOffAngleLdegreesstd','GaitLowerLimbToeOffAngleRdegreesmean','GaitLowerLimbToeOffAngleRdegreesstd','AvgToeoutangle','AsymmetryToeoutangle']\n",
    "SINGLE_LIMB_SUPPORT = ['GaitLowerLimbSingleLimbSupportLGCTmean','GaitLowerLimbSingleLimbSupportLGCTstd','GaitLowerLimbSingleLimbSupportRGCTmean','GaitLowerLimbSingleLimbSupportRGCTstd','AvgSinglelegsupportofGCT','AsymmetrySinglelegsupportofGCT']\n",
    "LIMB_STANCE = ['GaitLowerLimbStanceLGCTmean','GaitLowerLimbStanceLGCTstd','GaitLowerLimbStanceRGCTmean','GaitLowerLimbStanceRGCTstd','AvgStanceofGCT','AsymmetrystanceofGCT']\n",
    "STEP_DURATION = ['GaitLowerLimbStepDurationLsmean','GaitLowerLimbStepDurationLsstd','GaitLowerLimbStepDurationRsmean','GaitLowerLimbStepDurationRsstd','Avgstepduration','Asymmetrystepduration']\n",
    "STRIDE_LENGTH = ['GaitLowerLimbStrideLengthLmmean','GaitLowerLimbStrideLengthLmstd','GaitLowerLimbStrideLengthRmmean','GaitLowerLimbStrideLengthRmstd','Avgstridelength','Asymmetrystridelength']\n",
    "LIMB_SWING = ['GaitLowerLimbSwingLGCTmean','GaitLowerLimbSwingLGCTstd','GaitLowerLimbSwingRGCTmean','GaitLowerLimbSwingRGCTstd','AvgswingofGCT','AsymmetryswingofGCT']\n",
    "TERMINAL_DOUBLE_LIMB_SUPPORT_GCT = ['GaitLowerLimbTerminalDoubleSupportLGCTmean','GaitLowerLimbTerminalDoubleSupportLGCTstd','GaitLowerLimbTerminalDoubleSupportRGCTmean','GaitLowerLimbTerminalDoubleSupportRGCTstd','AvgterminaldoublelegsupportofGCT','AsymmetryterminaldoublelegsupportofGCT']\n",
    "TOE_OUT_ANGLE = ['GaitLowerLimbToeOutAngleLdegreesmean','GaitLowerLimbToeOutAngleLdegreesstd','GaitLowerLimbToeOutAngleRdegreesmean','GaitLowerLimbToeOutAngleRdegreesstd','AvgToeoutangle_A','AsymmetryAvgToeoutangle']\n",
    "LUMBER_ROM_IN_PLANES = ['GaitLumbarCoronalRangeofMotiondegreesmean','GaitLumbarCoronalRangeofMotiondegreesstd','GaitLumbarSagittalRangeofMotiondegreesmean','GaitLumbarSagittalRangeofMotiondegreesstd','GaitLumbarTransverseRangeofMotiondegreesmean','GaitLumbarTransverseRangeofMotiondegreesstd']\n",
    "TRUNK_POM_IN_PLANES = ['GaitTrunkCoronalRangeofMotiondegreesmean','GaitTrunkCoronalRangeofMotiondegreesstd','GaitTrunkSagittalRangeofMotiondegreesmean','GaitTrunkSagittalRangeofMotiondegreesstd','GaitTrunkTransverseRangeofMotiondegreesmean','GaitTrunkTransverseRangeofMotiondegreesstd','GaitUpperLimbArmSwingVelocityLdegreessmean','GaitUpperLimbArmSwingVelocityLdegreessstd','GaitUpperLimbArmSwingVelocityRdegreessmean','GaitUpperLimbArmSwingVelocityRdegreessstd','AvgUpperArmswingvelocity','Asymmetryupperarmswingvelocity']\n",
    "UPPER_LIMBS_ROM = ['GaitUpperLimbArmRangeofMotionLdegreesmean','GaitUpperLimbArmRangeofMotionLdegreesstd','GaitUpperLimbArmRangeofMotionRdegreesmean','GaitUpperLimbArmRangeofMotionRdegreesstd','AvgupperarmROM','AsymmetryupperarmROM']\n",
    "TURNS = ['TurnsAngledegreesmean','TurnsAngledegreesstd','TurnsDurationsmean','TurnsDurationsstd','TurnsN#','TurnsTurnVelocitydegreessmean','TurnsTurnVelocitydegreessstd','TurnsStepsinTurn#mean','TurnsStepsinTurn#std']\n",
    "Gait_SUBCATIGEROIES = ANTICEPATORY_POSTURE + BACK_ROM + NECK_ROM + CADENCE + DOUBLE_LIMB_SUPPORT_GCT + MIDSWING + GAIT_CYCLE_DURATION + GAIT_SPEED + GAIT_LATERAL_VARIATION + CIRCUMDUCTION_GAIT + FOOT_STRIKE + TOE_OFF + SINGLE_LIMB_SUPPORT + LIMB_STANCE + STEP_DURATION + STRIDE_LENGTH + LIMB_SWING + TERMINAL_DOUBLE_LIMB_SUPPORT_GCT + TOE_OUT_ANGLE + LUMBER_ROM_IN_PLANES + TRUNK_POM_IN_PLANES + UPPER_LIMBS_ROM + TURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance_Conditions\n",
    "Condition1 = [\"PosturalSwayAcc95EllipseAxis1Radiusms2\",\"PosturalSwayAcc95EllipseAxis2Radiusms2\",\"PosturalSwayAcc95EllipseRotationms2\",\n",
    "\"PosturalSwayAcc95EllipseSwayAream2s4\",\"PosturalSwayAccCentroidalFrequencyHz\",\"PosturalSwayAccCentroidalFrequencyCoronalHz\",\n",
    "\"PosturalSwayAccCentroidalFrequencySagittalHz\",\"PosturalSwayAccFrequencyDispersionAD\",\"PosturalSwayAccFrequencyDispersionCoronalAD\",\n",
    "\"PosturalSwayAccFrequencyDispersionSagittalAD\",\"PosturalSwayAccJerkm2s5\",\"PosturalSwayAccJerkCoronalm2s5\",\n",
    "\"PosturalSwayAccJerkSagittalm2s5\",\"PosturalSwayAccMeanVelocityms\",\"PosturalSwayAccMeanVelocityCoronalms\",\n",
    "\"PosturalSwayAccMeanVelocitySagittalms\",\"PosturalSwayAccPathLengthms2\",\"PosturalSwayAccPathLengthCoronalms2\",\n",
    "\"PosturalSwayAccPathLengthSagittalms2\",\"PosturalSwayAccRMSSwayms2\",\"PosturalSwayAccRMSSwayCoronalms2\",\n",
    "\"PosturalSwayAccRMSSwaySagittalms2\",\"PosturalSwayAccRangems2\",\"PosturalSwayAccRangeCoronalms2\",\"PosturalSwayAccRangeSagittalms2\",\n",
    "\"PosturalSwayAnglesSwayAreaRadiusCoronaldegrees\",\"PosturalSwayAngles95EllipseAxis2Radiusdegrees\",\n",
    "\"PosturalSwayAnglesSwayAreaRotationdegrees\", \"PosturalSwayAnglesSwayAreadegrees2\",\"PosturalSwayAnglesDurations\",\n",
    "\"PosturalSwayAnglesRMSSwaydegrees\",\"PosturalSwayAnglesRMSSwayCoronaldegrees\",\"PosturalSwayAnglesRMSSwaySagittaldegrees\"]\n",
    "Condition2 = [\"PosturalSwayAcc95EllipseAxis1Radiusms2_A\",\"PosturalSwayAcc95EllipseAxis2Radiusms2_A\",\"PosturalSwayAcc95EllipseRotationms2_A\",\n",
    "\"PosturalSwayAcc95EllipseSwayAream2s4_A\",\"PosturalSwayAccCentroidalFrequencyHz_A\",\"PosturalSwayAccCentroidalFrequencyCoronalHz_A\",\n",
    "\"PosturalSwayAccCentroidalFrequencySagittalHz_A\",\"PosturalSwayAccFrequencyDispersionAD_A\",\"PosturalSwayAccFrequencyDispersionCoronalAD_A\",\n",
    "\"PosturalSwayAccFrequencyDispersionSagittalAD_A\",\"PosturalSwayAccJerkm2s5_A\", \"PosturalSwayAccJerkCoronalm2s5_A\",\n",
    "\"PosturalSwayAccJerkSagittalm2s5_A\",\"PosturalSwayAccMeanVelocityms_A\",\"PosturalSwayAccMeanVelocityCoronalms_A\",\n",
    "\"PosturalSwayAccMeanVelocitySagittalms_A\",\"PosturalSwayAccPathLengthms2_A\",\"PosturalSwayAccPathLengthCoronalms2_A\",\n",
    "\"PosturalSwayAccPathLengthSagittalms2_A\",\"PosturalSwayAccRMSSwayms2_A\",\"PosturalSwayAccRMSSwayCoronalms2_A\",\n",
    "\"PosturalSwayAccRMSSwaySagittalms2_A\",\"PosturalSwayAccRangems2_A\",\"PosturalSwayAccRangeCoronalms2_A\",\n",
    "\"PosturalSwayAccRangeSagittalms2_A\",\"PosturalSwayAnglesSwayAreaRadiusCoronaldegrees_A\",\"PosturalSwayAngles95EllipseAxis2Radiusdegrees_A\",\n",
    "\"PosturalSwayAnglesSwayAreaRotationdegrees_A\",\"PosturalSwayAnglesSwayAreadegrees2_A\", \"PosturalSwayAnglesDurations_A\",\n",
    "\"PosturalSwayAnglesRMSSwaydegrees_A\",\"PosturalSwayAnglesRMSSwayCoronaldegrees_A\",\"PosturalSwayAnglesRMSSwaySagittaldegrees_A\"]\n",
    "Condition3 = [\"PosturalSwayAcc95EllipseAxis1Radiusms2_B\",\"PosturalSwayAcc95EllipseAxis2Radiusms2_B\", \"PosturalSwayAcc95EllipseRotationms2_B\",\n",
    "\"PosturalSwayAcc95EllipseSwayAream2s4_B\",\"PosturalSwayAccCentroidalFrequencyHz_B\",\"PosturalSwayAccCentroidalFrequencyCoronalHz_B\",\n",
    "\"PosturalSwayAccCentroidalFrequencySagittalHz_B\",\"PosturalSwayAccFrequencyDispersionAD_B\",\"PosturalSwayAccFrequencyDispersionCoronalAD_B\",\n",
    "\"PosturalSwayAccFrequencyDispersionSagittalAD_B\",\"PosturalSwayAccJerkm2s5_B\",\"PosturalSwayAccJerkCoronalm2s5_B\",\n",
    "\"PosturalSwayAccJerkSagittalm2s5_B\",\"PosturalSwayAccMeanVelocityms_B\",\"PosturalSwayAccMeanVelocityCoronalms_B\",\n",
    "\"PosturalSwayAccMeanVelocitySagittalms_B\",\"PosturalSwayAccPathLengthms2_B\",\"PosturalSwayAccPathLengthCoronalms2_B\",\n",
    "\"PosturalSwayAccPathLengthSagittalms2_B\",\"PosturalSwayAccRMSSwayms2_B\",\"PosturalSwayAccRMSSwayCoronalms2_B\",\n",
    "\"PosturalSwayAccRMSSwaySagittalms2_B\",\"PosturalSwayAccRangems2_B\",\"PosturalSwayAccRangeCoronalms2_B\",\n",
    "\"PosturalSwayAccRangeSagittalms2_B\",\"PosturalSwayAnglesSwayAreaRadiusCoronaldegrees_B\",\"PosturalSwayAngles95EllipseAxis2Radiusdegrees_B\",\n",
    "\"PosturalSwayAnglesSwayAreaRotationdegrees_B\",\"PosturalSwayAnglesSwayAreadegrees2_B\",\"PosturalSwayAnglesDurations_B\",\n",
    "\"PosturalSwayAnglesRMSSwaydegrees_B\",\"PosturalSwayAnglesRMSSwayCoronaldegrees_B\",\"PosturalSwayAnglesRMSSwaySagittaldegrees_B\"]\n",
    "Condition4 = [\"PosturalSwayAcc95EllipseAxis1Radiusms2_C\",\"PosturalSwayAcc95EllipseAxis2Radiusms2_C\",\n",
    "\"PosturalSwayAcc95EllipseRotationms2_C\",\"PosturalSwayAcc95EllipseSwayAream2s4_C\",\"PosturalSwayAccCentroidalFrequencyHz_C\",\n",
    "\"PosturalSwayAccCentroidalFrequencyCoronalHz_C\",\"PosturalSwayAccCentroidalFrequencySagittalHz_C\",\"PosturalSwayAccFrequencyDispersionAD_C\",\n",
    "\"PosturalSwayAccFrequencyDispersionCoronalAD_C\",\"PosturalSwayAccFrequencyDispersionSagittalAD_C\",\"PosturalSwayAccJerkm2s5_C\",\n",
    "\"PosturalSwayAccJerkCoronalm2s5_C\",\"PosturalSwayAccJerkSagittalm2s5_C\",\"PosturalSwayAccMeanVelocityms_C\",\n",
    "\"PosturalSwayAccMeanVelocityCoronalms_C\",\"PosturalSwayAccMeanVelocitySagittalms_C\",\n",
    "\"PosturalSwayAccPathLengthms2_C\",\"PosturalSwayAccPathLengthCoronalms2_C\",\"PosturalSwayAccPathLengthSagittalms2_C\",\n",
    "\"PosturalSwayAccRMSSwayms2_C\",\"PosturalSwayAccRMSSwayCoronalms2_C\",\"PosturalSwayAccRMSSwaySagittalms2_C\",\n",
    "\"PosturalSwayAccRangems2_C\",\"PosturalSwayAccRangeCoronalms2_C\",\"PosturalSwayAccRangeSagittalms2_C\",\n",
    "\"PosturalSwayAnglesSwayAreaRadiusCoronaldegrees_C\",\"PosturalSwayAngles95EllipseAxis2Radiusdegrees_C\",\n",
    "\"PosturalSwayAnglesSwayAreaRotationdegrees_C\",\"PosturalSwayAnglesSwayAreadegrees2_C\",\n",
    "\"PosturalSwayAnglesDurations_C\",\"PosturalSwayAnglesRMSSwaydegrees_C\",\"PosturalSwayAnglesRMSSwayCoronaldegrees_C\",\n",
    "\"PosturalSwayAnglesRMSSwaySagittaldegrees_C\"]\n",
    "Balance_Var = Condition1 + Condition2 + Condition3 + Condition4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Var = Y_Var+Demographic_var+Gait_SUBCATIGEROIES+Balance_Var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify X and Y s and making lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify X \n",
    "X_All = df.drop(Y_Var, axis=1)\n",
    "X_Gait = df.drop(Y_Var + Balance_Var, axis=1)\n",
    "X_Balance = df.drop(Y_Var + Gait_SUBCATIGEROIES, axis=1)\n",
    "X_Balance_C1 = df.drop(Y_Var + Gait_SUBCATIGEROIES + Condition2 + Condition3 + Condition4, axis=1)\n",
    "X_Balance_C2 = df.drop(Y_Var + Gait_SUBCATIGEROIES + Condition1 + Condition3 + Condition4, axis=1)\n",
    "X_Balance_C3 = df.drop(Y_Var + Gait_SUBCATIGEROIES + Condition2 + Condition1 + Condition4, axis=1)\n",
    "X_Balance_C4 = df.drop(Y_Var + Gait_SUBCATIGEROIES + Condition2 + Condition3 + Condition1, axis=1)\n",
    "X_list = [X_All,X_Gait,X_Balance,X_Balance_C1,X_Balance_C2,X_Balance_C3,X_Balance_C4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify Y\n",
    "Y_Class_Var = ['CurrentPOMSdepressionClasses']\n",
    "Y_POMSD = df['CurrentPOMSdepressionClasses']\n",
    "Y_list = [Y_POMSD]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# import necessary libraries\n",
    "#----------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "#----------------------------------------------------\n",
    "# Import Classifiers from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "#----------------------------------------------------\n",
    "# Import Regressors from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#----------------------------------------------------\n",
    "# Import model metrics from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import scipy.stats as st\n",
    "#----------------------------------------------------\n",
    "# Import Confusion matrix from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#----------------------------------------------------\n",
    "# Import ROC curve from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "#----------------------------------------------------\n",
    "# Import Model evaluation metrics from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Classifier Models\n",
    "#----------------------------------------------------\n",
    "RandomForestClassifierModel = RandomForestClassifier(criterion = 'gini', random_state=33) #criterion can be also : entropy \n",
    "MLPClassifierModel = MLPClassifier(activation='tanh', solver='lbfgs',  learning_rate='constant', early_stopping= False, alpha=0.0001 ,hidden_layer_sizes=(100, 3),random_state=33)\n",
    "DecisionTreeClassifierModel = DecisionTreeClassifier(criterion='gini',random_state=33) \n",
    "SVCModel = SVC(kernel= 'rbf', probability=True, C=1.0,gamma='auto')\n",
    "KNNClassifierModel = KNeighborsClassifier(n_neighbors= 5,weights ='uniform', algorithm='auto') \n",
    "GaussianNBModel = GaussianNB()\n",
    "LDAModel = LinearDiscriminantAnalysis()\n",
    "GradientBoostingClassifierModel = GradientBoostingClassifier( learning_rate=1.0, random_state=33) \n",
    "BaggingClassifierModel = BaggingClassifier(base_estimator=SVC(),  random_state=33)\n",
    "#----------------------------------------------------\n",
    "# Clasifier Models list\n",
    "#----------------------------------------------------\n",
    "Class_Model_list = [RandomForestClassifierModel, MLPClassifierModel, DecisionTreeClassifierModel, SVCModel,\n",
    "KNNClassifierModel, GaussianNBModel, LDAModel, GradientBoostingClassifierModel, BaggingClassifierModel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------\n",
    "# Defining Variables that inserted in the code\n",
    "#----------------------------------------------------\n",
    "Y_Class_Var_T = Y_Class_Var\n",
    "X_list_T = X_list\n",
    "Class_Model_list_T = Class_Model_list\n",
    "Top_feature_number = 12\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=30, random_state= 33)\n",
    "#----------------------------------------------------\n",
    "# Defining Empty dataframe for results\n",
    "#----------------------------------------------------\n",
    "results_df_class =pd.DataFrame(columns=['y','X_used','X_shape','feature_Selection_method','important_features_list',\n",
    "'important_feature_importances', 'Model_used', 'Model_used', 'Modelcheck_mean','Modelcheck_CI_testscore', \n",
    "'Modelcheck_min', 'Modelcheck_Q1', 'Modelcheck_Q2','Modelcheck_Q3','Modelcheck_max', 'roc_F1_score_mean_score',\n",
    "'roc_auc_mean_score', 'roc_percesion_mean_score','roc_sensetivity_mean_score','negative_log_likelihood','neg_log_loss'])\n",
    "#----------------------------------------------------\n",
    "# Creating for loop for y_name_list\n",
    "#----------------------------------------------------\n",
    "for y_name in Y_Class_Var_T:\n",
    "    y = df[y_name].values \n",
    "    for X in X_list_T:\n",
    "        X_columns_names = X.columns\n",
    "        if('GaitJointBackRightLat.BendMax.degreesmean'in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns):\n",
    "            X_used = \"Whole gait and Balance conditions\"\n",
    "        elif('GaitJointBackRightLat.BendMax.degreesmean'in X.columns):\n",
    "            X_used = \"Gait\"\n",
    "        elif ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns):\n",
    "            X_used = \"Whole Balance conditions\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2' in X.columns:\n",
    "            X_used = \"Condition1\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns:\n",
    "            X_used = \"Condition2\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns:\n",
    "            X_used = \"Condition3\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns:\n",
    "            X_used = \"Condition4\"\n",
    "        for Model_name in Class_Model_list_T:\n",
    "            # Test and Train separation\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=33, shuffle =False)\n",
    "            # Feature selection application\n",
    "            Model_name.fit(X, y)\n",
    "            # Get importance weights\n",
    "            from sklearn.inspection import permutation_importance\n",
    "            Model_name.score(X_test, y_test)       \n",
    "            # IF statement\n",
    "            importance = permutation_importance (Model_name, X_test, y_test, n_repeats=5, random_state=33)\n",
    "            importance = importance.importances_mean\n",
    "            feature_Selection_method = \"permutation\"\n",
    "            # Get features names with their weights\n",
    "            feats = {} \n",
    "            for feature, importance in zip(X_columns_names, importance):\n",
    "                feats[feature] = importance  \n",
    "            importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'importance'})\n",
    "            # Sort features with top 12 important feature at the top\n",
    "            importanc_df = importances.sort_values(by ='importance' ,ascending=False).head(Top_feature_number)\n",
    "            # Create feature names list\n",
    "            important_features_list = importanc_df.index.tolist()\n",
    "            important_feature_importances = importanc_df.importance.tolist()\n",
    "            # Create important features dataframe\n",
    "            important_features_df = pd.DataFrame()\n",
    "            # Insert values in dataframe\n",
    "            for K in important_features_list:\n",
    "                important_features_df = important_features_df.append(df[K])\n",
    "            important_features_df = important_features_df.transpose()\n",
    "            XIF = important_features_df\n",
    "            #XIF = important_features_df.values\n",
    "            # Make X list\n",
    "            X_list_int = [X, XIF]\n",
    "            for Xroll in X_list_int:\n",
    "                X_shape = Xroll.shape\n",
    "                #Splitting data\n",
    "                X_train, X_test, y_train, y_test = train_test_split(Xroll, y, test_size=0.10, random_state=33, shuffle =True)\n",
    "                # K-Fold method method\n",
    "                CrossValidateValues1 = cross_validate(Model_name,Xroll,y,cv=cv,return_train_score = True, n_jobs=-1)\n",
    "                Modelcheck_trainscore = CrossValidateValues1['train_score']\n",
    "                Modelcheck_testscore = CrossValidateValues1['test_score'] \n",
    "                Modelcheck_mean_testscore = CrossValidateValues1['test_score'].mean() \n",
    "                Modelcheck_CI_testscore = st.t.interval(alpha=0.95, df=len(Modelcheck_testscore)-1, loc=np.mean(Modelcheck_testscore), scale=st.sem(Modelcheck_testscore))\n",
    "                Modelcheck_min_testscore = CrossValidateValues1['test_score'].min() \n",
    "                Modelcheck_max_testscore = CrossValidateValues1['test_score'].max() \n",
    "                test_score_Q1 = np.quantile(Modelcheck_testscore, .25)\n",
    "                test_score_Q2 = np.quantile(Modelcheck_testscore, .50)\n",
    "                test_score_Q3 = np.quantile(Modelcheck_testscore, .75)\n",
    "                Modelcheck_fitscore = CrossValidateValues1['fit_time']\n",
    "                roc_F1_score_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"f1_macro\", cv = cv, n_jobs= -1).mean()\n",
    "                roc_auc_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"roc_auc_ovo\", cv = cv, n_jobs= -1).mean()\n",
    "                roc_percesion_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"precision_macro\", cv = cv, n_jobs= -1).mean()\n",
    "                roc_sensetivity_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"recall_macro\", cv = cv, n_jobs= -1).mean()\n",
    "                negative_log_likelihood1 = cross_val_score(Model_name, Xroll, y, scoring=\"neg_brier_score\", cv = cv, n_jobs= -1)\n",
    "                neg_log_loss1 = cross_val_score(Model_name, Xroll, y, scoring=\"neg_log_loss\", cv = cv, n_jobs= -1)\n",
    "                neg_log_loss = np.median(neg_log_loss1)\n",
    "                negative_log_likelihood = np.median(negative_log_likelihood1)\n",
    "                # Insert results in dataframe\n",
    "                results_df_class = results_df_class.append({'X_shape': X_shape,'y': y_name,'X_used': X_used,'important_features_list': important_features_list, \n",
    "                'important_feature_importances':important_feature_importances, 'Model_used':Model_name, 'feature_Selection_method': feature_Selection_method,           \n",
    "                'Modelcheck_mean': Modelcheck_mean_testscore,'Modelcheck_CI_testscore' : Modelcheck_CI_testscore, \n",
    "                'Modelcheck_min': Modelcheck_min_testscore, 'Modelcheck_Q1': test_score_Q1, 'Modelcheck_Q2': test_score_Q2,\n",
    "                'Modelcheck_Q3': test_score_Q3,'Modelcheck_max': Modelcheck_max_testscore, \n",
    "                'roc_F1_score_mean_score': roc_F1_score_mean_score,'roc_auc_mean_score': roc_auc_mean_score, \n",
    "                'roc_percesion_mean_score': roc_percesion_mean_score,'roc_sensetivity_mean_score': roc_sensetivity_mean_score,\n",
    "                'negative_log_likelihood': negative_log_likelihood,'neg_log_loss': neg_log_loss}, ignore_index=True)\n",
    "#----------------------------------------------------\n",
    "# Export the results to the excel\n",
    "#----------------------------------------------------\n",
    "EXPORT_PATH = r'/content/Depression_Gait_balance/Models/Model Results/results_df_class.xlsx'\n",
    "results_df_class.to_excel(EXPORT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the best classifier model Choosing the best n of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Defining Variables that inserted in the code\n",
    "#----------------------------------------------------\n",
    "Y_Class_Var_T = Y_Class_Var\n",
    "X_list_T = [X_list[2]]\n",
    "Class_Model_list_T = Class_Model_list[0]\n",
    "Top_feature_number = 12\n",
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats= 2, random_state= 33)\n",
    "#----------------------------------------------------\n",
    "# Defining Empty dataframe for results\n",
    "#----------------------------------------------------\n",
    "results_df_class_Bestn =pd.DataFrame(columns=['y','X_used','X_shape','number','feature_Selection_method','important_features_list',\n",
    "'important_feature_importances', 'Model_used', 'Model_used', 'Modelcheck_mean','Modelcheck_CI_testscore', \n",
    "'Modelcheck_min', 'Modelcheck_Q1', 'Modelcheck_Q2','Modelcheck_Q3','Modelcheck_max', 'roc_F1_score_mean_score',\n",
    "'roc_auc_mean_score', 'roc_percesion_mean_score','roc_sensetivity_mean_score','negative_log_likelihood','neg_log_loss'])\n",
    "#----------------------------------------------------\n",
    "# Creating for loop for y_name_list\n",
    "#----------------------------------------------------\n",
    "for y_name in Y_Class_Var_T:\n",
    "    y = df[y_name].values \n",
    "    for X in X_list_T:\n",
    "        X_columns_names = X.columns\n",
    "        if('GaitJointBackRightLat.BendMax.degreesmean'in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns):\n",
    "            X_used = \"Whole gait and Balance conditions\"\n",
    "        elif('GaitJointBackRightLat.BendMax.degreesmean'in X.columns):\n",
    "            X_used = \"Gait\"\n",
    "        elif ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns):\n",
    "            X_used = \"Whole Balance conditions\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2' in X.columns:\n",
    "            X_used = \"Condition1\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns:\n",
    "            X_used = \"Condition2\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns:\n",
    "            X_used = \"Condition3\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns:\n",
    "            X_used = \"Condition4\"\n",
    "        for Model_name in Class_Model_list_T:\n",
    "            # Test and Train separation\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=33, shuffle =False)\n",
    "            # Feature selection application\n",
    "            Model_name.fit(X, y)\n",
    "            # Get importance weights\n",
    "            from sklearn.inspection import permutation_importance\n",
    "            Model_name.score(X_test, y_test)       \n",
    "            # IF statement\n",
    "            importance = permutation_importance (Model_name, X_test, y_test, n_repeats=5, random_state=33)\n",
    "            importance = importance.importances_mean\n",
    "            feature_Selection_method = \"permutation\"\n",
    "            # Get features names with their weights\n",
    "            feats = {} \n",
    "            for feature, importance in zip(X_columns_names, importance):\n",
    "                feats[feature] = importance  \n",
    "            importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'importance'})\n",
    "            for number in range (2,Top_feature_number):\n",
    "                # Sort features with top 12 important feature at the top\n",
    "                importanc_df = importances.sort_values(by ='importance' ,ascending=False).head(Top_feature_number)\n",
    "                # Create feature names list\n",
    "                important_features_list = importanc_df.index.tolist()\n",
    "                important_feature_importances = importanc_df.importance.tolist()\n",
    "                # Create important features dataframe\n",
    "                important_features_df = pd.DataFrame()\n",
    "                # Insert values in dataframe\n",
    "                for K in important_features_list:\n",
    "                    important_features_df = important_features_df.append(df[K])\n",
    "                important_features_df = important_features_df.transpose()\n",
    "                XIF = important_features_df\n",
    "                #XIF = important_features_df.values\n",
    "                # Make X list\n",
    "                X_list_int = [XIF]\n",
    "                for Xroll in X_list_int:\n",
    "                    X_shape = Xroll.shape\n",
    "                    #Splitting data\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(Xroll, y, test_size=0.10, random_state=33, shuffle =True)\n",
    "                    # K-Fold method method\n",
    "                    CrossValidateValues1 = cross_validate(Model_name,Xroll,y,cv=cv,return_train_score = True, n_jobs=-1)\n",
    "                    Modelcheck_trainscore = CrossValidateValues1['train_score']\n",
    "                    Modelcheck_testscore = CrossValidateValues1['test_score'] \n",
    "                    Modelcheck_mean_testscore = CrossValidateValues1['test_score'].mean() \n",
    "                    Modelcheck_CI_testscore = st.t.interval(alpha=0.95, df=len(Modelcheck_testscore)-1, loc=np.mean(Modelcheck_testscore), scale=st.sem(Modelcheck_testscore))\n",
    "                    Modelcheck_min_testscore = CrossValidateValues1['test_score'].min() \n",
    "                    Modelcheck_max_testscore = CrossValidateValues1['test_score'].max() \n",
    "                    test_score_Q1 = np.quantile(Modelcheck_testscore, .25)\n",
    "                    test_score_Q2 = np.quantile(Modelcheck_testscore, .50)\n",
    "                    test_score_Q3 = np.quantile(Modelcheck_testscore, .75)\n",
    "                    Modelcheck_fitscore = CrossValidateValues1['fit_time']\n",
    "                    roc_F1_score_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"f1_macro\", cv = cv, n_jobs= -1).mean()\n",
    "                    roc_auc_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"roc_auc_ovo\", cv = cv, n_jobs= -1).mean()\n",
    "                    roc_percesion_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"precision_macro\", cv = cv, n_jobs= -1).mean()\n",
    "                    roc_sensetivity_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"recall_macro\", cv = cv, n_jobs= -1).mean()\n",
    "                    negative_log_likelihood1 = cross_val_score(Model_name, Xroll, y, scoring=\"neg_brier_score\", cv = cv, n_jobs= -1)\n",
    "                    neg_log_loss1 = cross_val_score(Model_name, Xroll, y, scoring=\"neg_log_loss\", cv = cv, n_jobs= -1)\n",
    "                    neg_log_loss = np.median(neg_log_loss1)\n",
    "                    negative_log_likelihood = np.median(negative_log_likelihood1)\n",
    "                    # Insert results in dataframe\n",
    "                    results_df_class_Bestn = results_df_class_Bestn.append({'X_shape': X_shape,'y': y_name,'X_used': X_used,'important_features_list': important_features_list, \n",
    "                    'important_feature_importances':important_feature_importances, 'Model_used':Model_name, \n",
    "                    'number': number,'feature_Selection_method': feature_Selection_method,           \n",
    "                    'Modelcheck_mean': Modelcheck_mean_testscore,'Modelcheck_CI_testscore' : Modelcheck_CI_testscore, \n",
    "                    'Modelcheck_min': Modelcheck_min_testscore, 'Modelcheck_Q1': test_score_Q1, 'Modelcheck_Q2': test_score_Q2,\n",
    "                    'Modelcheck_Q3': test_score_Q3,'Modelcheck_max': Modelcheck_max_testscore, \n",
    "                    'roc_F1_score_mean_score': roc_F1_score_mean_score,'roc_auc_mean_score': roc_auc_mean_score, \n",
    "                    'roc_percesion_mean_score': roc_percesion_mean_score,'roc_sensetivity_mean_score': roc_sensetivity_mean_score,\n",
    "                    'negative_log_likelihood': negative_log_likelihood,'neg_log_loss': neg_log_loss}, ignore_index=True)\n",
    "#----------------------------------------------------\n",
    "# Export the results to the excel\n",
    "#----------------------------------------------------\n",
    "EXPORT_PATH = r'/content/Depression_Gait_balance/Models/Model Results/results_df_class_Bestn.xlsx'\n",
    "results_df_class_Bestn.to_excel(EXPORT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of the best Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88033ea6e6aaf353f3d26ef69434bb9b1f089d6b00d896155ae24c39a5d92896"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
